import os
import cv2
import tkinter.messagebox  # To pop up the message
import pickle
import face_recognition
import numpy as np
import cvzone
import firebase_admin
from firebase_admin import credentials
from firebase_admin import db
from firebase_admin import storage
from datetime import datetime

cred = credentials.Certificate("ServiceAccountKey.json")
firebase_admin.initialize_app(cred,{
    'databaseURL':"https://humandetection-43fa7-default-rtdb.asia-southeast1.firebasedatabase.app/",
    'storageBucket':"humandetection-43fa7.appspot.com"
})

bucket = storage.bucket()

def detect(path):
    face = cv2.CascadeClassifier("./haarcascade_fullbody.xml")
    # web cam setup
    cam = cv2.VideoCapture(path)
    cam.set(3, 740)
    cam.set(4, 480)

    # modes' folder is opening here   
    foldermodepath = './modes'  # Use forward slash (/) for paths
    modePathList = os.listdir(foldermodepath)
    imgmodelist = []
    # here we are creating mode list to show modes to user
    for mode_file in modePathList:
        imgmodelist.append(cv2.imread(os.path.join(foldermodepath, mode_file)))

    # assinging background image to project
    imgbackground = cv2.imread("HACKTHON PROJECT.png")


    # To pop the message window
    tkinter.messagebox.showinfo("Welcome to Human Detection System.", "Press 'a' to close the upcoming video screen")

    print("Loading the encoded file.....")
    # Load the encoding file
    with open("encodefile.p", "rb") as file:
        encodelistknownwithIDs = pickle.load(file)
    # splinting the encodelistknownwithIDs into id and encodedlistitem
    encodelistknown, personIDs = encodelistknownwithIDs
    print("Loaded the encoded file.....")

    # assing the initial values to cariables
    modechanger = 0 #helps to switch between modes
    PersonInfo=[]#pers's info will be stored here
    counter=0 
    id=-1 #stores the id to be shown
    imgperson=[] #stres image that have to be shown 
    while True:
        ret, img = cam.read()#camrea read here
        if not ret:
            print("Error: Failed to capture frame.")
            break

        imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)#resizing the web cam output        
        imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)#color change 
        #actual face recognition is started
        faceCurFrame = face_recognition.face_locations(imgS) 
        # Detecting the face
        enocdeCurrFrame = face_recognition.face_encodings(imgS, faceCurFrame)
        #actual face recognition is ended

        img = cv2.resize(img, (740, 480))
        imgbackground[150:150+480, 50:50+740] = img  # Adding webcam part to background
        imgmodelist[modechanger] = cv2.resize(imgmodelist[modechanger], (410, 383))
        imgbackground[45:45 + 383, 860:860 + 410, :] = imgmodelist[modechanger]  # Adding mode to the project
        #unxziping the data generated by face_recognition
        for encodeface, faceLoc in zip(enocdeCurrFrame, faceCurFrame):
            #matchning started
            matches = face_recognition.compare_faces(encodelistknown, encodeface)
            facedis = face_recognition.face_distance(encodelistknown, encodeface)
            #matching ended
            # print("matches", matches)
            # print("facedis", facedis)
            #here we are finding the minimum face distance

            matchIndex = np.argmin(facedis)

            # matchindex is the index which is detected
            # print("Match Index is: ",matchIndex)
            if matches[matchIndex]:
                # personIDs[matchIndex]
                # adding square to web cam  jo face detect krta hai
                y1,x2,y2,x1 = faceLoc
                y1,x2,y2,x1 = y1*4 ,x2*4 ,y2*4 ,x1*4  
                bbox=60+x1,150+y1,x2-x1,y2-y1
                imgbackground=cvzone.cornerRect(imgbackground,bbox,rt=0)
                # id jo images ko di hai vo ispe store hogi
                id = personIDs[matchIndex]
                # print(id)
                if counter == 0:
                    counter=1
                    modechanger=1
                    imgbackground[45:45 + 383, 860:860 + 410, :] = imgmodelist[modechanger]
        if counter != 0:
            #yha first frame pe data downloade ho rha hai server se
            if counter ==1:
                # get the data
                PersonInfo = db.reference(f'data_of_people/{id}').get()
                # get the image from data base
                blob = bucket.get_blob(f'person/{id}.jpeg')
                array = np.frombuffer(blob.download_as_string(),np.uint8)
                imgperson = cv2.imdecode(array,cv2.COLOR_BGRA2BGR)
                # update data of the last time detected
                detectedtime=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                ref = db.reference(f'data_of_people/{id}')
                ref.child('LastDetectedTime').set(detectedtime)


            if counter<=30:
                # adding the data to output window
                # name
                (w,h),_=cv2.getTextSize(PersonInfo['name'],cv2.FONT_HERSHEY_COMPLEX,1,1)
                offset = (453-w)//2
                cv2.putText(imgbackground,str(PersonInfo['name']),(855+offset,100),cv2.FONT_HERSHEY_DUPLEX,1,(0,0,0),2)

                # other field
                cv2.putText(imgbackground,str(PersonInfo['LastDetectedTime']),(1003,330),cv2.FONT_HERSHEY_DUPLEX,0.5,(0,0,0),1)
                cv2.putText(imgbackground,str(PersonInfo['reason']),(988,365),cv2.FONT_HERSHEY_DUPLEX,1,(0,0,0),2)


                imgperson = cv2.resize(imgperson, (160, 160))
                imgbackground[110:110+160,993:993+160] = imgperson

            counter+=1
            #reseting the dependent vriables
            if counter>=30:
                counter=0
                modechanger=0
                PersonInfo=[]
                imgperson = []
                imgbackground[45:45 + 383, 860:860 + 410, :] = imgmodelist[modechanger]
        
        # yha pe  actual project show ho rha hai 
        cv2.imshow("Human_detect", imgbackground)
        #wait ki se image ko roka ja sakta hai 
        if cv2.waitKey(10) == ord("a"):
            break #to end the project click a
    #releases the cam  and all windowns 
    cam.release()
    cv2.destroyAllWindows()

# to run the code endlessly
while True:
    flag = input("\n1) Detect humans through External Cams (webcam)\n2) Detect humans through Prestored Video\n3) exit\nEnter your choice(1 or 2 or 3): ")

    if flag == "1":
        detect(0)  # Use 0 to indicate the default camera (webcam)
    elif flag == "2":
        path = input("Enter path with video name: ")
        detect(path)
    elif flag == "3":
        break
    else:
        print("!!INVALID OPERATION!!, please enter valid operation (1 or 2 or 3)\n")
